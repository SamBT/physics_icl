{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c88485e4-2340-4886-b753-684752badbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#%matplotlib inline\n",
    "from PhysicsDatasets import SHODatasetXV, DampedSHODatasetXV, DampedSHODatasetV2\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import json\n",
    "from matplotlib.colors import LogNorm, Normalize\n",
    "from utils import load_model\n",
    "import utils\n",
    "import os\n",
    "from datetime import datetime\n",
    "import yaml\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import plotting as ptools\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbac7c43-a716-483e-b1a1-6154da8caff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nrow = 4\\nncol = len(masses)//4 + 1*int(len(masses)%4 > 0)\\nfig,axes = plt.subplots(4,ncol,figsize=(ncol*8,nrow*6))\\nbeta_test = 0\\nib = list(betas).index(beta_test)\\nn_ctx_test = 50\\n\\nfor i,m_test in enumerate(masses):\\n    plt.sca(axes.flatten()[i])\\n    im = list(masses).index(m_test)\\n    cmap = plt.get_cmap(\\'viridis\\')\\n    colors = [cmap(i / (len(iter_ckpts) - 1)) for i in range(len(iter_ckpts))]\\n\\n    plt.plot(ks,loss_best[n_ctx_test-1,im,:,ib],color=\\'red\\')\\n    for ii,n_iter in enumerate(iter_ckpts):\\n        plt.plot(ks,loss_byIter[n_iter][n_ctx_test-1,im,:,ib],color=colors[ii])\\n    #plt.yscale(\\'log\\')\\n    plt.title(f\"M = {m_test}\")'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [\"tokenized_discrete_mkb_mAll_kAll_betaAll\"]#,\"tokenized_discrete_mkb_mLo_kAll_betaAll\",\"tokenized_discrete_mkb_mHi_kAll_betaAll\",\"tokenized_discrete_mkb_mLoHi_kAll_betaAll\"]\n",
    "\n",
    "data = {}\n",
    "for m in models:\n",
    "    model_dir = ptools.get_latest_model_dir(m)\n",
    "    results = [f for f in os.listdir(model_dir) if \"iter\" in f and \".npy\" in f]\n",
    "    n_iters = [int(re.search(\"iter(\\d+)\",m).group(1)) for m in results]\n",
    "    data[m] = {}\n",
    "    for n in n_iters:\n",
    "        data[m][n] = np.load(f\"{model_dir}/eval_iter{n}.npy\")\n",
    "    masses = np.load(f\"{model_dir}/eval_masses.npy\")\n",
    "    ks = np.load(f\"{model_dir}/eval_ks.npy\")\n",
    "    betas = np.load(f\"{model_dir}/eval_betas.npy\")\n",
    "\n",
    "\"\"\"nrow = 4\n",
    "ncol = len(masses)//4 + 1*int(len(masses)%4 > 0)\n",
    "fig,axes = plt.subplots(4,ncol,figsize=(ncol*8,nrow*6))\n",
    "beta_test = 0\n",
    "ib = list(betas).index(beta_test)\n",
    "n_ctx_test = 50\n",
    "\n",
    "for i,m_test in enumerate(masses):\n",
    "    plt.sca(axes.flatten()[i])\n",
    "    im = list(masses).index(m_test)\n",
    "    cmap = plt.get_cmap('viridis')\n",
    "    colors = [cmap(i / (len(iter_ckpts) - 1)) for i in range(len(iter_ckpts))]\n",
    "\n",
    "    plt.plot(ks,loss_best[n_ctx_test-1,im,:,ib],color='red')\n",
    "    for ii,n_iter in enumerate(iter_ckpts):\n",
    "        plt.plot(ks,loss_byIter[n_iter][n_ctx_test-1,im,:,ib],color=colors[ii])\n",
    "    #plt.yscale('log')\n",
    "    plt.title(f\"M = {m_test}\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ac2d82-0008-45f7-90ac-1596536a1083",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mamba-torch_gpu]",
   "language": "python",
   "name": "conda-env-mamba-torch_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
