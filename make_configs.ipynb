{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4a5a7b9-bbc6-4c04-952c-bd9c0f9e3c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import yaml\n",
    "import copy\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdd4f92-55aa-472a-b1cf-f95fec62fa7d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Discrete masses, spring constants, and betas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e722d11f-a9da-4ba9-8d73-718a34a65ccb",
   "metadata": {},
   "source": [
    "## with RoPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77f52360-0b97-4236-9dd1-39766024cdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('configs/discrete_mass_k_beta/default_discrete_mass_k_beta.yaml','r') as fin:\n",
    "    default_config = yaml.safe_load(fin)\n",
    "\n",
    "m_vals = dict(\n",
    "    mAll=[1,2,3,4,5,6,7,8,9,10],\n",
    "    mLo=[1,2,3,4,5],\n",
    "    mHi=[6,7,8,9,10],\n",
    "    mLoHi=[1,2,3,8,9,10],\n",
    ")\n",
    "\n",
    "k_vals = dict(\n",
    "    kAll=[10,11,12,13,14,15,16,17,18,19,20],\n",
    "    kLo=[10,11,12,13,14,15],\n",
    "    kHi=[16,17,18,19,20],\n",
    "    kLoHi=[10,11,12,13,17,18,19,20],\n",
    ")\n",
    "\n",
    "beta_vals = dict(\n",
    "    betaAll=[0,1,2,3,4],\n",
    "    beta0=[0],\n",
    "    betaLo=[0,1,2],\n",
    "    betaHi=[2,3,4],\n",
    "    betaLoHi=[0,1,3,4]\n",
    ")\n",
    "\n",
    "cfg = []\n",
    "for bval in beta_vals.keys():\n",
    "    for kval in k_vals.keys():\n",
    "        for mval in m_vals.keys():\n",
    "            name=f\"{mval}_{kval}_{bval}\"\n",
    "            config = copy.deepcopy(default_config)\n",
    "            config['model_name'] = f\"discrete_mkb_{name}\"\n",
    "            config['dataset_params']['m'] = m_vals[mval]\n",
    "            config['dataset_params']['k'] = k_vals[kval]\n",
    "            config['dataset_params']['beta'] = beta_vals[bval]\n",
    "\n",
    "            with open(f\"configs/discrete_mass_k_beta/discrete_mkb_{name}.yaml\",\"w\") as fout:\n",
    "                yaml.safe_dump(config,fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db38ce6c-7fab-4469-ad0a-5daf37c6cda9",
   "metadata": {},
   "source": [
    "## without RoPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80c6a74a-3b9f-4028-9e08-17aa96b4224b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"configs/discrete_mass_k_beta/\"\n",
    "tgt = \"configs/discrete_mass_k_beta_noRoPE/\"\n",
    "all_yamls = [f for f in os.listdir(base) if '.yaml' in f]\n",
    "os.makedirs(tgt,exist_ok=True)\n",
    "\n",
    "for yml in all_yamls:\n",
    "    config = yaml.safe_load(open(f\"{base}/{yml}\",\"r\"))\n",
    "    config['model_params']['use_rope'] = False\n",
    "    config['model_name'] = config['model_name'] + \"_noRoPE\"\n",
    "    yaml.safe_dump(config,open(f\"{tgt}/{yml.split('.')[0]}_noRoPE.yaml\",\"w\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22543c3-4343-4beb-8166-c08dffa4d7a4",
   "metadata": {},
   "source": [
    "## with RoPE, tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdb5e4f0-55b0-44ba-85af-99f4f72dc904",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('configs/default.yaml','r') as fin:\n",
    "    default_config = yaml.safe_load(fin)\n",
    "\n",
    "if not os.path.isdir(\"configs/tokenized_discrete_mkb\"):\n",
    "    os.makedirs(\"configs/tokenized_discrete_mkb\",exist_ok=True)\n",
    "\n",
    "m_vals = dict(\n",
    "    mAll=[1,2,3,4,5,6,7,8,9,10],\n",
    "    mLo=[1,2,3,4,5],\n",
    "    mHi=[6,7,8,9,10],\n",
    "    mLoHi=[1,2,3,8,9,10],\n",
    ")\n",
    "\n",
    "k_vals = dict(\n",
    "    kAll=[10,11,12,13,14,15,16,17,18,19,20],\n",
    "    kLo=[10,11,12,13,14,15],\n",
    "    kHi=[16,17,18,19,20],\n",
    "    kLoHi=[10,11,12,13,17,18,19,20],\n",
    ")\n",
    "\n",
    "beta_vals = dict(\n",
    "    betaAll=[0,1,2,3,4],\n",
    "    beta0=[0],\n",
    "    betaLo=[0,1,2],\n",
    "    betaHi=[2,3,4],\n",
    "    betaLoHi=[0,1,3,4]\n",
    ")\n",
    "\n",
    "cfg = []\n",
    "for bval in beta_vals.keys():\n",
    "    for kval in k_vals.keys():\n",
    "        for mval in m_vals.keys():\n",
    "            name=f\"{mval}_{kval}_{bval}\"\n",
    "            config = copy.deepcopy(default_config)\n",
    "            config['model_name'] = f\"tokenized_discrete_mkb_{name}\"\n",
    "            config['dataset_params']['m'] = m_vals[mval]\n",
    "            config['dataset_params']['k'] = k_vals[kval]\n",
    "            config['dataset_params']['beta'] = beta_vals[bval]\n",
    "            config['dataset_params']['xv'] = False\n",
    "            config['model_params']['tokenized'] = True\n",
    "\n",
    "            config['parsing_params']['m_tuple'] = False\n",
    "            config['parsing_params']['k_tuple'] = False\n",
    "            config['parsing_params']['beta_tuple'] = False\n",
    "\n",
    "            with open(f\"configs/tokenized_discrete_mkb/tokenized_discrete_mkb_{name}.yaml\",\"w\") as fout:\n",
    "                yaml.safe_dump(config,fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722cf015-0c0d-40a3-a49f-4adfff65fb37",
   "metadata": {},
   "source": [
    "## without RoPE, tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a6103b1-5b78-48a8-b2c5-0f980fbfcef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('configs/default.yaml','r') as fin:\n",
    "    default_config = yaml.safe_load(fin)\n",
    "\n",
    "if not os.path.isdir(\"configs/tokenized_discrete_mkb_noRoPE\"):\n",
    "    os.makedirs(\"configs/tokenized_discrete_mkb_noRoPE\",exist_ok=True)\n",
    "\n",
    "m_vals = dict(\n",
    "    mAll=[1,2,3,4,5,6,7,8,9,10],\n",
    "    mLo=[1,2,3,4,5],\n",
    "    mHi=[6,7,8,9,10],\n",
    "    mLoHi=[1,2,3,8,9,10],\n",
    ")\n",
    "\n",
    "k_vals = dict(\n",
    "    kAll=[10,11,12,13,14,15,16,17,18,19,20],\n",
    "    kLo=[10,11,12,13,14,15],\n",
    "    kHi=[16,17,18,19,20],\n",
    "    kLoHi=[10,11,12,13,17,18,19,20],\n",
    ")\n",
    "\n",
    "beta_vals = dict(\n",
    "    betaAll=[0,1,2,3,4],\n",
    "    beta0=[0],\n",
    "    betaLo=[0,1,2],\n",
    "    betaHi=[2,3,4],\n",
    "    betaLoHi=[0,1,3,4]\n",
    ")\n",
    "\n",
    "cfg = []\n",
    "for bval in beta_vals.keys():\n",
    "    for kval in k_vals.keys():\n",
    "        for mval in m_vals.keys():\n",
    "            name=f\"{mval}_{kval}_{bval}\"\n",
    "            config = copy.deepcopy(default_config)\n",
    "            config['model_name'] = f\"tokenized_discrete_mkb_{name}_noRoPE\"\n",
    "            config['dataset_params']['m'] = m_vals[mval]\n",
    "            config['dataset_params']['k'] = k_vals[kval]\n",
    "            config['dataset_params']['beta'] = beta_vals[bval]\n",
    "            config['dataset_params']['xv'] = False\n",
    "            config['model_params']['tokenized'] = True\n",
    "\n",
    "            config['parsing_params']['m_tuple'] = False\n",
    "            config['parsing_params']['k_tuple'] = False\n",
    "            config['parsing_params']['beta_tuple'] = False\n",
    "\n",
    "            config['model_params']['use_rope'] = False\n",
    "\n",
    "            with open(f\"configs/tokenized_discrete_mkb_noRoPE/tokenized_discrete_mkb_{name}_noRoPE.yaml\",\"w\") as fout:\n",
    "                yaml.safe_dump(config,fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c129f6f7-8cb3-44f0-95a5-099a7750d8e6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Continuous masses, spring constants, and betas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfa8eb5-8587-41fd-80e7-f06a3e515254",
   "metadata": {},
   "source": [
    "## with RoPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7db71b23-0176-4667-b5dd-0c234208c778",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('configs/continuous_mkb/default_continuous_mkb.yaml','r') as fin:\n",
    "    default_config = yaml.safe_load(fin)\n",
    "\n",
    "m_vals = dict(\n",
    "    mAll=[1,10],\n",
    "    mLo=[1,5],\n",
    "    mHi=[5,10],\n",
    "    mLoHi=[[1,3],[8,10]],\n",
    ")\n",
    "\n",
    "k_vals = dict(\n",
    "    kAll=[10,20],\n",
    "    kLo=[10,15],\n",
    "    kHi=[15,20],\n",
    "    kLoHi=[[10,13],[17,20]],\n",
    ")\n",
    "\n",
    "beta_vals = dict(\n",
    "    betaAll=[0,4],\n",
    "    beta0=[0,0],\n",
    "    betaLo=[0,2],\n",
    "    betaHi=[2,4],\n",
    "    betaLoHi=[[0,1],[3,4]],\n",
    ")\n",
    "\n",
    "cfg = []\n",
    "for bval in beta_vals.keys():\n",
    "    for kval in k_vals.keys():\n",
    "        for mval in m_vals.keys():\n",
    "            name=f\"{mval}_{kval}_{bval}\"\n",
    "            config = copy.deepcopy(default_config)\n",
    "            config['model_name'] = f\"continuous_mkb_{name}\"\n",
    "            config['dataset_params']['m'] = m_vals[mval]\n",
    "            config['dataset_params']['k'] = k_vals[kval]\n",
    "            config['dataset_params']['beta'] = beta_vals[bval]\n",
    "\n",
    "            with open(f\"configs/continuous_mkb/continuous_mkb_{name}.yaml\",\"w\") as fout:\n",
    "                yaml.safe_dump(config,fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6244d73-d4a1-4935-be58-99e3c3a9d3eb",
   "metadata": {},
   "source": [
    "## without RoPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e06cf3d-3697-4106-85b7-73ea4f23043d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"configs/continuous_mkb/\"\n",
    "tgt = \"configs/continuous_mkb_noRoPE/\"\n",
    "all_yamls = [f for f in os.listdir(base) if '.yaml' in f]\n",
    "os.makedirs(tgt,exist_ok=True)\n",
    "\n",
    "for yml in all_yamls:\n",
    "    config = yaml.safe_load(open(f\"{base}/{yml}\",\"r\"))\n",
    "    config['model_params']['use_rope'] = False\n",
    "    config['model_name'] = config['model_name'] + \"_noRoPE\"\n",
    "    yaml.safe_dump(config,open(f\"{tgt}/{yml.split('.')[0]}_noRoPE.yaml\",\"w\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580c5795-c9a9-4e53-8f7d-144b3db0e6a2",
   "metadata": {},
   "source": [
    "## with RoPE, tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6d7b51f-746d-4634-b6c4-c3c1616a5d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('configs/default.yaml','r') as fin:\n",
    "    default_config = yaml.safe_load(fin)\n",
    "\n",
    "if not os.path.isdir(\"configs/tokenized_continuous_mkb\"):\n",
    "    os.makedirs(\"configs/tokenized_continuous_mkb\",exist_ok=True)\n",
    "\n",
    "m_vals = dict(\n",
    "    mAll=[1,10],\n",
    "    mLo=[1,5],\n",
    "    mHi=[5,10],\n",
    "    mLoHi=[[1,3],[8,10]],\n",
    ")\n",
    "\n",
    "k_vals = dict(\n",
    "    kAll=[10,20],\n",
    "    kLo=[10,15],\n",
    "    kHi=[15,20],\n",
    "    kLoHi=[[10,13],[17,20]],\n",
    ")\n",
    "\n",
    "beta_vals = dict(\n",
    "    betaAll=[0,4],\n",
    "    beta0=[0,0],\n",
    "    betaLo=[0,2],\n",
    "    betaHi=[2,4],\n",
    "    betaLoHi=[[0,1],[3,4]],\n",
    ")\n",
    "\n",
    "cfg = []\n",
    "for bval in beta_vals.keys():\n",
    "    for kval in k_vals.keys():\n",
    "        for mval in m_vals.keys():\n",
    "            name=f\"{mval}_{kval}_{bval}\"\n",
    "            config = copy.deepcopy(default_config)\n",
    "            config['model_name'] = f\"tokenized_continuous_mkb_{name}\"\n",
    "            config['dataset_params']['m'] = m_vals[mval]\n",
    "            config['dataset_params']['k'] = k_vals[kval]\n",
    "            config['dataset_params']['beta'] = beta_vals[bval]\n",
    "            config['dataset_params']['xv'] = False\n",
    "            config['model_params']['tokenized'] = True\n",
    "\n",
    "            config['parsing_params']['m_tuple'] = True\n",
    "            config['parsing_params']['k_tuple'] = True\n",
    "            config['parsing_params']['beta_tuple'] = True\n",
    "\n",
    "            with open(f\"configs/tokenized_continuous_mkb/tokenized_continuous_mkb_{name}.yaml\",\"w\") as fout:\n",
    "                yaml.safe_dump(config,fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ba9d8a-aef1-41cc-b0a5-6e18253365f5",
   "metadata": {},
   "source": [
    "## without RoPE, tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30cf8f7d-eb0c-4f4b-a698-416a6950f3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('configs/default.yaml','r') as fin:\n",
    "    default_config = yaml.safe_load(fin)\n",
    "\n",
    "if not os.path.isdir(\"configs/tokenized_continuous_mkb_noRoPE\"):\n",
    "    os.makedirs(\"configs/tokenized_continuous_mkb_noRoPE\",exist_ok=True)\n",
    "\n",
    "m_vals = dict(\n",
    "    mAll=[1,10],\n",
    "    mLo=[1,5],\n",
    "    mHi=[5,10],\n",
    "    mLoHi=[[1,3],[8,10]],\n",
    ")\n",
    "\n",
    "k_vals = dict(\n",
    "    kAll=[10,20],\n",
    "    kLo=[10,15],\n",
    "    kHi=[15,20],\n",
    "    kLoHi=[[10,13],[17,20]],\n",
    ")\n",
    "\n",
    "beta_vals = dict(\n",
    "    betaAll=[0,4],\n",
    "    beta0=[0,0],\n",
    "    betaLo=[0,2],\n",
    "    betaHi=[2,4],\n",
    "    betaLoHi=[[0,1],[3,4]],\n",
    ")\n",
    "\n",
    "cfg = []\n",
    "for bval in beta_vals.keys():\n",
    "    for kval in k_vals.keys():\n",
    "        for mval in m_vals.keys():\n",
    "            name=f\"{mval}_{kval}_{bval}\"\n",
    "            config = copy.deepcopy(default_config)\n",
    "            config['model_name'] = f\"tokenized_continuous_mkb_{name}_noRoPE\"\n",
    "            config['dataset_params']['m'] = m_vals[mval]\n",
    "            config['dataset_params']['k'] = k_vals[kval]\n",
    "            config['dataset_params']['beta'] = beta_vals[bval]\n",
    "            config['dataset_params']['xv'] = False\n",
    "            config['model_params']['tokenized'] = True\n",
    "\n",
    "            config['parsing_params']['m_tuple'] = True\n",
    "            config['parsing_params']['k_tuple'] = True\n",
    "            config['parsing_params']['beta_tuple'] = True\n",
    "\n",
    "            config['model_params']['use_rope'] = False\n",
    "\n",
    "            with open(f\"configs/tokenized_continuous_mkb_noRoPE/tokenized_continuous_mkb_{name}_noRoPE.yaml\",\"w\") as fout:\n",
    "                yaml.safe_dump(config,fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f4bc2a-8b3b-4f72-ada9-5e8e9655247b",
   "metadata": {},
   "source": [
    "# Set and vary $w_0$ rather than $(m,k)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f905a2da-d743-45af-acf3-359defc232ce",
   "metadata": {},
   "source": [
    "## With MSE loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca212899-df38-47cc-8786-68ca8edc6e9a",
   "metadata": {},
   "source": [
    "### continuous ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d10f8cb-887f-4771-bef4-739208b930a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('configs/default_mse.yaml','r') as fin:\n",
    "    default_config = yaml.load(fin,Loader=yaml.FullLoader)\n",
    "\n",
    "outDir = \"configs/mse/varyW0Beta_continuous/\"\n",
    "name_prefix= \"mse_continuousW0Beta\"\n",
    "os.makedirs(outDir,exist_ok=True)\n",
    "\n",
    "w0_vals = dict(\n",
    "    wAll=(0.1,4),\n",
    "    wLo=(0.1,2),\n",
    "    wHi=(2,4),\n",
    "    wLoHi=[(0.1,2),(3,4)],\n",
    ")\n",
    "\n",
    "beta_vals = dict(\n",
    "    betaAll=(0,4),\n",
    "    beta0=0,\n",
    "    betaLo=(0,2),\n",
    "    betaHi=(2,4),\n",
    "    betaLoHi=[(0,2),(3,4)]\n",
    ")\n",
    "\n",
    "cfg = []\n",
    "for bval in beta_vals.keys():\n",
    "    for wval in w0_vals.keys():\n",
    "        name=f\"{wval}_{bval}\"\n",
    "        config = copy.deepcopy(default_config)\n",
    "        config['model_name'] = f\"{name_prefix}_{name}\"\n",
    "        config['dataset_params']['m'] = None\n",
    "        config['dataset_params']['k'] = None\n",
    "        config['dataset_params']['beta'] = beta_vals[bval]\n",
    "        config['dataset_params']['w0'] = w0_vals[wval]\n",
    "\n",
    "        with open(f\"{outDir}/{name_prefix}_{name}.yaml\",\"w\") as fout:\n",
    "            yaml.dump(config,fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d18c57e-caec-46e2-af1b-1f30179e6ba0",
   "metadata": {},
   "source": [
    "### continuous, RoPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5223b64-ffb5-419e-9b74-1b60cb0830d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('configs/default_mse.yaml','r') as fin:\n",
    "    default_config = yaml.load(fin,Loader=yaml.FullLoader)\n",
    "\n",
    "outDir = \"configs/mse/varyW0Beta_continuous_RoPE/\"\n",
    "name_prefix= \"mse_continuousW0Beta_RoPE\"\n",
    "os.makedirs(outDir,exist_ok=True)\n",
    "\n",
    "w0_vals = dict(\n",
    "    wAll=(0.1,4),\n",
    "    wLo=(0.1,2),\n",
    "    wHi=(2,4),\n",
    "    wLoHi=[(0.1,2),(3,4)],\n",
    ")\n",
    "\n",
    "beta_vals = dict(\n",
    "    betaAll=(0,4),\n",
    "    beta0=0,\n",
    "    betaLo=(0,2),\n",
    "    betaHi=(2,4),\n",
    "    betaLoHi=[(0,2),(3,4)]\n",
    ")\n",
    "\n",
    "cfg = []\n",
    "for bval in beta_vals.keys():\n",
    "    for wval in w0_vals.keys():\n",
    "        name=f\"{wval}_{bval}\"\n",
    "        config = copy.deepcopy(default_config)\n",
    "        config['model_name'] = f\"{name_prefix}_{name}\"\n",
    "        config['dataset_params']['m'] = None\n",
    "        config['dataset_params']['k'] = None\n",
    "        config['dataset_params']['beta'] = beta_vals[bval]\n",
    "        config['dataset_params']['w0'] = w0_vals[wval]\n",
    "\n",
    "        config['model_params']['use_rope'] = True\n",
    "\n",
    "        with open(f\"{outDir}/{name_prefix}_{name}.yaml\",\"w\") as fout:\n",
    "            yaml.dump(config,fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f76aa0-8460-4430-bbf2-0ed660766ba2",
   "metadata": {},
   "source": [
    "### discrete ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d79af9fd-94b4-4c08-9045-7a410bd91f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('configs/default_mse.yaml','r') as fin:\n",
    "    default_config = yaml.load(fin,Loader=yaml.FullLoader)\n",
    "\n",
    "outDir = \"configs/mse/varyW0Beta_discrete/\"\n",
    "name_prefix= \"mse_discreteW0Beta\"\n",
    "os.makedirs(outDir,exist_ok=True)\n",
    "\n",
    "w0_vals = dict(\n",
    "    wAll=[0.1,1,2,3,4],\n",
    "    wLo=[0.1,1,2],\n",
    "    wHi=[2,3,4],\n",
    "    wLoHi=[0.1,1,3,4],\n",
    ")\n",
    "\n",
    "beta_vals = dict(\n",
    "    betaAll=[0,1,2,3,4],\n",
    "    beta0=0,\n",
    "    betaLo=[0,1,2],\n",
    "    betaHi=[2,3,4],\n",
    "    betaLoHi=[0,1,3,4]\n",
    ")\n",
    "\n",
    "cfg = []\n",
    "for bval in beta_vals.keys():\n",
    "    for wval in w0_vals.keys():\n",
    "        name=f\"{wval}_{bval}\"\n",
    "        config = copy.deepcopy(default_config)\n",
    "        config['model_name'] = f\"{name_prefix}_{name}\"\n",
    "        config['dataset_params']['m'] = None\n",
    "        config['dataset_params']['k'] = None\n",
    "        config['dataset_params']['beta'] = beta_vals[bval]\n",
    "        config['dataset_params']['w0'] = w0_vals[wval]\n",
    "\n",
    "        with open(f\"{outDir}/{name_prefix}_{name}.yaml\",\"w\") as fout:\n",
    "            yaml.dump(config,fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d55827-d936-4a2b-ad42-84c13f2d2f2f",
   "metadata": {},
   "source": [
    "### continuous ranges, pin amplitude = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa624239-e9a9-46cd-b73a-5ff8366bc5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('configs/default_mse.yaml','r') as fin:\n",
    "    default_config = yaml.load(fin,Loader=yaml.FullLoader)\n",
    "\n",
    "outDir = \"configs/mse/varyW0Beta_continuous_pinAmp1/\"\n",
    "name_prefix= \"mse_continuousW0Beta_pinAmp1\"\n",
    "os.makedirs(outDir,exist_ok=True)\n",
    "\n",
    "w0_vals = dict(\n",
    "    wAll=(0.1,4),\n",
    "    wLo=(0.1,2),\n",
    "    wHi=(2,4),\n",
    "    wLoHi=[(0.1,2),(3,4)],\n",
    ")\n",
    "\n",
    "beta_vals = dict(\n",
    "    betaAll=(0,4),\n",
    "    beta0=0,\n",
    "    betaLo=(0,2),\n",
    "    betaHi=(2,4),\n",
    "    betaLoHi=[(0,2),(3,4)]\n",
    ")\n",
    "\n",
    "cfg = []\n",
    "for bval in beta_vals.keys():\n",
    "    for wval in w0_vals.keys():\n",
    "        name=f\"{wval}_{bval}\"\n",
    "        config = copy.deepcopy(default_config)\n",
    "        config['model_name'] = f\"{name_prefix}_{name}\"\n",
    "        config['dataset_params']['m'] = None\n",
    "        config['dataset_params']['k'] = None\n",
    "        config['dataset_params']['beta'] = beta_vals[bval]\n",
    "        config['dataset_params']['w0'] = w0_vals[wval]\n",
    "        config['dataset_params']['pin_amplitude'] = 1.0\n",
    "\n",
    "        with open(f\"{outDir}/{name_prefix}_{name}.yaml\",\"w\") as fout:\n",
    "            yaml.dump(config,fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de5e4f8-d4a1-42d2-b4a9-ae26b263e0e5",
   "metadata": {},
   "source": [
    "### continuous ranges, tiny 1-head model with 4 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1406067f-5db6-48d2-921b-ad7f0aefe24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('configs/default_mse.yaml','r') as fin:\n",
    "    default_config = yaml.load(fin,Loader=yaml.FullLoader)\n",
    "\n",
    "outDir = \"configs/mse/tinyModel_varyW0Beta_continuous/\"\n",
    "name_prefix= \"mse_tinyModel_continuousW0Beta\"\n",
    "os.makedirs(outDir,exist_ok=True)\n",
    "\n",
    "w0_vals = dict(\n",
    "    wAll=(0.1,4),\n",
    "    wLo=(0.1,2),\n",
    "    wHi=(2,4),\n",
    "    wLoHi=[(0.1,2),(3,4)],\n",
    ")\n",
    "\n",
    "beta_vals = dict(\n",
    "    betaAll=(0,4),\n",
    "    beta0=0,\n",
    "    betaLo=(0,2),\n",
    "    betaHi=(2,4),\n",
    "    betaLoHi=[(0,2),(3,4)]\n",
    ")\n",
    "\n",
    "cfg = []\n",
    "for bval in beta_vals.keys():\n",
    "    for wval in w0_vals.keys():\n",
    "        name=f\"{wval}_{bval}\"\n",
    "        config = copy.deepcopy(default_config)\n",
    "        config['model_name'] = f\"{name_prefix}_{name}\"\n",
    "        config['dataset_params']['m'] = None\n",
    "        config['dataset_params']['k'] = None\n",
    "        config['dataset_params']['beta'] = beta_vals[bval]\n",
    "        config['dataset_params']['w0'] = w0_vals[wval]\n",
    "\n",
    "        config['model_params']['n_layer'] = 4\n",
    "        config['model_params']['n_head'] = 1\n",
    "\n",
    "        with open(f\"{outDir}/{name_prefix}_{name}.yaml\",\"w\") as fout:\n",
    "            yaml.dump(config,fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea19cdec-abb7-4f38-a726-bdefb382bc35",
   "metadata": {},
   "source": [
    "### continuous ranges, larger 1 head model with 8 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5d684c3-dbf6-4f5f-9dd6-a10b7ed0619f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('configs/default_mse.yaml','r') as fin:\n",
    "    default_config = yaml.load(fin,Loader=yaml.FullLoader)\n",
    "\n",
    "outDir = \"configs/mse/L8H1_varyW0Beta_continuous/\"\n",
    "name_prefix= \"mse_L8H1_continuousW0Beta\"\n",
    "os.makedirs(outDir,exist_ok=True)\n",
    "\n",
    "w0_vals = dict(\n",
    "    wAll=(0.1,4),\n",
    "    wLo=(0.1,2),\n",
    "    wHi=(2,4),\n",
    "    wLoHi=[(0.1,2),(3,4)],\n",
    ")\n",
    "\n",
    "beta_vals = dict(\n",
    "    betaAll=(0,4),\n",
    "    beta0=0,\n",
    "    betaLo=(0,2),\n",
    "    betaHi=(2,4),\n",
    "    betaLoHi=[(0,2),(3,4)]\n",
    ")\n",
    "\n",
    "cfg = []\n",
    "for bval in beta_vals.keys():\n",
    "    for wval in w0_vals.keys():\n",
    "        name=f\"{wval}_{bval}\"\n",
    "        config = copy.deepcopy(default_config)\n",
    "        config['model_name'] = f\"{name_prefix}_{name}\"\n",
    "        config['dataset_params']['m'] = None\n",
    "        config['dataset_params']['k'] = None\n",
    "        config['dataset_params']['beta'] = beta_vals[bval]\n",
    "        config['dataset_params']['w0'] = w0_vals[wval]\n",
    "\n",
    "        config['model_params']['n_layer'] = 8\n",
    "        config['model_params']['n_head'] = 1\n",
    "\n",
    "        with open(f\"{outDir}/{name_prefix}_{name}.yaml\",\"w\") as fout:\n",
    "            yaml.dump(config,fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048e8f1b-b54c-4a1f-ad08-08f994d9ed29",
   "metadata": {},
   "source": [
    "### continuous ranges, L = 8, H = 2, 50k training steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "354099e1-e8ec-467b-9792-1a8243d007de",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('configs/default_mse.yaml','r') as fin:\n",
    "    default_config = yaml.load(fin,Loader=yaml.FullLoader)\n",
    "\n",
    "outDir = \"configs/mse/L8H2_train50ksteps_varyW0Beta_continuous/\"\n",
    "name_prefix= \"mse_L8H2_train50ksteps_continuousW0Beta\"\n",
    "os.makedirs(outDir,exist_ok=True)\n",
    "\n",
    "w0_vals = dict(\n",
    "    wAll=(0.1,4),\n",
    "    wLo=(0.1,2),\n",
    "    wHi=(2,4),\n",
    "    wLoHi=[(0.1,2),(3,4)],\n",
    ")\n",
    "\n",
    "beta_vals = dict(\n",
    "    betaAll=(0,4),\n",
    "    beta0=0,\n",
    "    betaLo=(0,2),\n",
    "    betaHi=(2,4),\n",
    "    betaLoHi=[(0,2),(3,4)]\n",
    ")\n",
    "\n",
    "cfg = []\n",
    "for bval in beta_vals.keys():\n",
    "    for wval in w0_vals.keys():\n",
    "        name=f\"{wval}_{bval}\"\n",
    "        config = copy.deepcopy(default_config)\n",
    "        config['model_name'] = f\"{name_prefix}_{name}\"\n",
    "        config['dataset_params']['m'] = None\n",
    "        config['dataset_params']['k'] = None\n",
    "        config['dataset_params']['beta'] = beta_vals[bval]\n",
    "        config['dataset_params']['w0'] = w0_vals[wval]\n",
    "\n",
    "        config['model_params']['n_layer'] = 8\n",
    "        config['model_params']['n_head'] = 2\n",
    "\n",
    "        config['training_params']['num_train_iters'] = 50_000\n",
    "\n",
    "        with open(f\"{outDir}/{name_prefix}_{name}.yaml\",\"w\") as fout:\n",
    "            yaml.dump(config,fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23af99fe-1764-43cb-9c3b-7671519272d9",
   "metadata": {},
   "source": [
    "### continuous ranges, L = 8, H = 2, 50k training steps, vary dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a93aa16-c92e-4fa0-94cb-caab908b96df",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('configs/default_mse.yaml','r') as fin:\n",
    "    default_config = yaml.load(fin,Loader=yaml.FullLoader)\n",
    "\n",
    "outDir = \"configs/mse/L8H2_train50ksteps_varyDt_varyW0Beta_continuous/\"\n",
    "name_prefix= \"mse_L8H2_train50ksteps_varyDt_continuousW0Beta\"\n",
    "os.makedirs(outDir,exist_ok=True)\n",
    "\n",
    "w0_vals = dict(\n",
    "    wAll=(0.1,4),\n",
    "    wLo=(0.1,2),\n",
    "    wHi=(2,4),\n",
    "    wLoHi=[(0.1,2),(3,4)],\n",
    ")\n",
    "\n",
    "beta_vals = dict(\n",
    "    betaAll=(0,4),\n",
    "    beta0=0,\n",
    "    betaLo=(0,2),\n",
    "    betaHi=(2,4),\n",
    "    betaLoHi=[(0,2),(3,4)]\n",
    ")\n",
    "\n",
    "cfg = []\n",
    "for bval in beta_vals.keys():\n",
    "    for wval in w0_vals.keys():\n",
    "        name=f\"{wval}_{bval}\"\n",
    "        config = copy.deepcopy(default_config)\n",
    "        config['model_name'] = f\"{name_prefix}_{name}\"\n",
    "        config['dataset_params']['m'] = None\n",
    "        config['dataset_params']['k'] = None\n",
    "        config['dataset_params']['beta'] = beta_vals[bval]\n",
    "        config['dataset_params']['w0'] = w0_vals[wval]\n",
    "        config['dataset_params']['dt'] = (0.05,0.15)\n",
    "        config['dataset_params']['seq_len'] = 256\n",
    "\n",
    "        config['model_params']['n_layer'] = 8\n",
    "        config['model_params']['n_head'] = 2\n",
    "\n",
    "        config['training_params']['num_train_iters'] = 50_000\n",
    "            \n",
    "        with open(f\"{outDir}/{name_prefix}_{name}.yaml\",\"w\") as fout:\n",
    "            yaml.dump(config,fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17af0127-41f5-4ab0-966d-1418c2ba6876",
   "metadata": {},
   "source": [
    "## Tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e1df4e-819c-4dc2-ba68-4f95f2d61b90",
   "metadata": {},
   "source": [
    "### continuous ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c3c48df-5ebe-41ac-8b8f-9a9b51aead16",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('configs/default_tokenized.yaml','r') as fin:\n",
    "    default_config = yaml.load(fin,Loader=yaml.FullLoader)\n",
    "\n",
    "outDir = \"configs/tokenized/varyW0Beta_continuous/\"\n",
    "name_prefix= \"tokenized_continuousW0Beta\"\n",
    "os.makedirs(outDir,exist_ok=True)\n",
    "\n",
    "w0_vals = dict(\n",
    "    wAll=(0.1,4),\n",
    "    wLo=(0.1,2),\n",
    "    wHi=(2,4),\n",
    "    wLoHi=[(0.1,2),(3,4)],\n",
    ")\n",
    "\n",
    "beta_vals = dict(\n",
    "    betaAll=(0,4),\n",
    "    beta0=0,\n",
    "    betaLo=(0,2),\n",
    "    betaHi=(2,4),\n",
    "    betaLoHi=[(0,2),(3,4)]\n",
    ")\n",
    "\n",
    "cfg = []\n",
    "for bval in beta_vals.keys():\n",
    "    for wval in w0_vals.keys():\n",
    "        name=f\"{wval}_{bval}\"\n",
    "        config = copy.deepcopy(default_config)\n",
    "        config['model_name'] = f\"{name_prefix}_{name}\"\n",
    "        config['dataset_params']['m'] = None\n",
    "        config['dataset_params']['k'] = None\n",
    "        config['dataset_params']['beta'] = beta_vals[bval]\n",
    "        config['dataset_params']['w0'] = w0_vals[wval]\n",
    "\n",
    "        with open(f\"{outDir}/{name_prefix}_{name}.yaml\",\"w\") as fout:\n",
    "            yaml.dump(config,fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ed2d77-3ad8-4937-9ba4-923fbd8dd713",
   "metadata": {},
   "source": [
    "### discrete ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0fea8bc-86d1-4052-b874-3ae85b283c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('configs/default_tokenized.yaml','r') as fin:\n",
    "    default_config = yaml.load(fin,Loader=yaml.FullLoader)\n",
    "\n",
    "outDir = \"configs/tokenized/varyW0Beta_discrete/\"\n",
    "name_prefix= \"tokenized_discreteW0Beta\"\n",
    "os.makedirs(outDir,exist_ok=True)\n",
    "\n",
    "w0_vals = dict(\n",
    "    wAll=[0.1,1,2,3,4],\n",
    "    wLo=[0.1,1,2],\n",
    "    wHi=[2,3,4],\n",
    "    wLoHi=[0.1,1,3,4],\n",
    ")\n",
    "\n",
    "beta_vals = dict(\n",
    "    betaAll=[0,1,2,3,4],\n",
    "    beta0=0,\n",
    "    betaLo=[0,1,2],\n",
    "    betaHi=[2,3,4],\n",
    "    betaLoHi=[0,1,3,4]\n",
    ")\n",
    "\n",
    "cfg = []\n",
    "for bval in beta_vals.keys():\n",
    "    for wval in w0_vals.keys():\n",
    "        name=f\"{wval}_{bval}\"\n",
    "        config = copy.deepcopy(default_config)\n",
    "        config['model_name'] = f\"{name_prefix}_{name}\"\n",
    "        config['dataset_params']['m'] = None\n",
    "        config['dataset_params']['k'] = None\n",
    "        config['dataset_params']['beta'] = beta_vals[bval]\n",
    "        config['dataset_params']['w0'] = w0_vals[wval]\n",
    "\n",
    "        with open(f\"{outDir}/{name_prefix}_{name}.yaml\",\"w\") as fout:\n",
    "            yaml.dump(config,fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d28ad0b-c130-4de6-8b16-f7fe75af702f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch]",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
